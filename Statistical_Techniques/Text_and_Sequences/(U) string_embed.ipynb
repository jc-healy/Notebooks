{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION: UNCLASSIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import random\n",
    "from glob import glob\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using doc2vec to embed your strings into a vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load unclassified data\n",
    "\n",
    "fnames = glob('/mypath/Dictionary/*')\n",
    "\n",
    "words = list()\n",
    "for fname in fnames:\n",
    "    f = open(fname, 'rb').readlines()\n",
    "    for ln in f:\n",
    "        ln = ln.strip()\n",
    "        if len(ln) > 0:\n",
    "            ln = ln.split()\n",
    "            try:\n",
    "                word = ln[0].lower().decode('utf8')\n",
    "                words.append(word)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sample 1000\n",
    "\n",
    "words = random.sample(words, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circumgyration',\n",
       " 'resourceless',\n",
       " 'dynamism',\n",
       " 'enbattled',\n",
       " 'cross-tining',\n",
       " 'conservant',\n",
       " 'conglutinate',\n",
       " 'individualizing',\n",
       " 'tintinnabulary',\n",
       " 'focuses']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# doc2vec requires docs to be a list of TaggedDocuments\n",
    "# Our words will be single letter, and the document will be a word\n",
    "\n",
    "# We also create a mapping between the word and ID\n",
    "\n",
    "word2id = dict()\n",
    "id2word = dict()\n",
    "docs = list()\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    doc = [ch for ch in word]\n",
    "    docs.append(TaggedDocument(doc, [i]))\n",
    "    word2id[word] = i\n",
    "    id2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['c', 'i', 'r', 'c', 'u', 'm', 'g', 'y', 'r', 'a', 't', 'i', 'o', 'n'], tags=[0]),\n",
       " TaggedDocument(words=['r', 'e', 's', 'o', 'u', 'r', 'c', 'e', 'l', 'e', 's', 's'], tags=[1]),\n",
       " TaggedDocument(words=['d', 'y', 'n', 'a', 'm', 'i', 's', 'm'], tags=[2]),\n",
       " TaggedDocument(words=['e', 'n', 'b', 'a', 't', 't', 'l', 'e', 'd'], tags=[3]),\n",
       " TaggedDocument(words=['c', 'r', 'o', 's', 's', '-', 't', 'i', 'n', 'i', 'n', 'g'], tags=[4]),\n",
       " TaggedDocument(words=['c', 'o', 'n', 's', 'e', 'r', 'v', 'a', 'n', 't'], tags=[5]),\n",
       " TaggedDocument(words=['c', 'o', 'n', 'g', 'l', 'u', 't', 'i', 'n', 'a', 't', 'e'], tags=[6]),\n",
       " TaggedDocument(words=['i', 'n', 'd', 'i', 'v', 'i', 'd', 'u', 'a', 'l', 'i', 'z', 'i', 'n', 'g'], tags=[7]),\n",
       " TaggedDocument(words=['t', 'i', 'n', 't', 'i', 'n', 'n', 'a', 'b', 'u', 'l', 'a', 'r', 'y'], tags=[8]),\n",
       " TaggedDocument(words=['f', 'o', 'c', 'u', 's', 'e', 's'], tags=[9])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the docs\n",
    "\n",
    "docs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Intialize the model\n",
    "\n",
    "model=Doc2Vec(size=100, window=3, min_count=1, workers=1)  \n",
    "model.build_vocab(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['c', 'i', 'r', 'u', 'm', 'g', 'y', 'a', 't', 'o', 'n', 'e', 's', 'l', 'd', 'b', '-', 'v', 'z', 'f', 'k', 'h', 'x', 'w', 'j', 'p', \"'\", 'q', '/', '\\\\', '8', '9', '1'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model vocabulary:\n",
    "\n",
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Doc2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3a174fc30fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Load model from disk:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_doc2vec.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Doc2vec' is not defined"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "for epoch in range(5000):  \n",
    "    if epoch%100==0:\n",
    "        print(epoch, end=\",\")  \n",
    "    random.shuffle(docs) # shuffling improves accuracy  \n",
    "    model.train(docs,total_examples=model.corpus_count,epochs=model.iter)\n",
    "# Save morel to disk:\n",
    "model.save('my_doc2vec.model')\n",
    "\n",
    "#Load model from disk:\n",
    "loaded_model = Doc2vec.load('my_doc2vec.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> carnate\n",
      "catenarian 0.8770938515663147\n",
      "catenary 0.8148835897445679\n",
      "cantrap 0.7034035325050354\n",
      "errantia 0.679182767868042\n",
      "aret 0.6783150434494019\n",
      "recharter 0.6721259951591492\n",
      "earthen 0.6616954803466797\n",
      "ecrasement 0.6581054925918579\n",
      "ramenta 0.6570524573326111\n",
      "nictitate 0.6551100015640259\n"
     ]
    }
   ],
   "source": [
    "# Examine results\n",
    "\n",
    "sampled_word = random.sample(word2id.keys(), 1)[0]\n",
    "word_id = word2id[sampled_word]\n",
    "\n",
    "print('->', sampled_word)\n",
    "for i,dist in model.docvecs.most_similar(word_id):\n",
    "    print(id2word[i], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0252908 , -0.00184963,  0.01034822, -0.0725349 , -0.00036861,\n",
       "       -0.05427065,  0.05543349,  0.04705929,  0.13685465, -0.05237833,\n",
       "       -0.02433972, -0.1571064 , -0.04413479, -0.01799181,  0.05554555,\n",
       "        0.02819999,  0.12372626,  0.00089496,  0.02137826,  0.02530239,\n",
       "        0.04476873,  0.06453766,  0.13744074, -0.03069505, -0.01986267,\n",
       "        0.01688043, -0.00165788, -0.03812186,  0.05609811,  0.01070709,\n",
       "        0.0530517 , -0.05096143, -0.01210093, -0.02673788,  0.04528841,\n",
       "       -0.10980565, -0.04488931,  0.02754822,  0.03489595,  0.01706621,\n",
       "        0.00252509,  0.1012056 ,  0.00429634, -0.18010156, -0.0336314 ,\n",
       "        0.05466712,  0.12280104,  0.11435528, -0.01919638, -0.00593638,\n",
       "        0.07689813,  0.03652444, -0.0299679 , -0.08849475, -0.09305425,\n",
       "       -0.07621914, -0.04179749,  0.11866371,  0.06045969, -0.0659438 ,\n",
       "       -0.05988073,  0.05995956,  0.1161134 , -0.08249649, -0.01848164,\n",
       "       -0.11880788, -0.02720426, -0.02820082,  0.02717019,  0.09928929,\n",
       "       -0.0422909 , -0.06253789, -0.03125466, -0.05475405,  0.09738265,\n",
       "        0.12295795,  0.05106996,  0.22195651,  0.05831519, -0.01463581,\n",
       "       -0.01751178, -0.077444  ,  0.08770661, -0.14569148, -0.02327121,\n",
       "        0.08931763, -0.00325796, -0.00488998,  0.00849932,  0.02544585,\n",
       "       -0.02193024, -0.05423998,  0.01664124,  0.00904375,  0.07706474,\n",
       "        0.07471246, -0.07978833,  0.02449367, -0.04834325,  0.12523516], dtype=float32)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict an unseen word\n",
    "\n",
    "model.infer_vector([ch for ch in 'thishasnotbeenseen'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91290402e-02,  -2.15354100e-01,  -1.03427410e+00,\n",
       "        -6.47459447e-01,   5.85198939e-01,  -6.40803218e-01,\n",
       "         1.72562733e-01,   6.07906356e-02,   4.58596051e-01,\n",
       "        -3.16858202e-01,  -5.66073740e-03,   6.82961822e-01,\n",
       "        -5.71416795e-01,   1.23959756e+00,   2.74155408e-01,\n",
       "         2.79298872e-01,  -8.95022631e-01,   2.47595951e-01,\n",
       "         3.59667465e-02,  -1.85420945e-01,   1.50854373e+00,\n",
       "        -4.36332017e-01,  -1.90419659e-01,  -4.27732825e-01,\n",
       "         3.58692795e-01,   3.24834399e-02,  -3.35018784e-01,\n",
       "         6.44691408e-01,  -6.48786962e-01,  -1.43860149e+00,\n",
       "        -3.20353627e-01,   5.65001547e-01,  -9.71344292e-01,\n",
       "        -1.03948092e+00,   4.56681848e-01,  -1.51573360e+00,\n",
       "        -1.92424446e-01,  -2.48525694e-01,   2.82247037e-01,\n",
       "        -4.21614408e-01,  -1.54514927e-02,  -7.26724982e-01,\n",
       "        -1.30672359e+00,  -5.56172729e-01,  -5.76018989e-01,\n",
       "         6.63460791e-02,  -1.08765316e+00,   7.51016364e-02,\n",
       "        -6.02600873e-01,   2.94485390e-01,   9.03124809e-01,\n",
       "        -1.88421440e+00,  -3.22931021e-01,  -6.94629133e-01,\n",
       "        -1.19136822e+00,  -2.03908372e+00,  -1.27829999e-01,\n",
       "        -1.18492496e+00,  -1.49719641e-01,  -1.43846643e+00,\n",
       "        -2.30005908e+00,   1.14703548e+00,  -1.58509195e+00,\n",
       "         9.03644025e-01,  -1.93078887e+00,  -1.86297342e-01,\n",
       "        -8.40209052e-02,  -4.41252500e-01,   1.38651502e+00,\n",
       "        -6.70916200e-01,  -1.29936814e-01,   1.00323796e+00,\n",
       "         3.02659839e-01,   9.50120568e-01,  -4.48083073e-01,\n",
       "         1.12732005e+00,   1.62660658e-01,   1.47212636e+00,\n",
       "         8.87090049e-04,  -5.90462685e-01,   3.66481900e-01,\n",
       "        -2.12586343e-01,  -3.23497027e-01,  -1.53987372e+00,\n",
       "        -1.46316707e+00,   5.76067805e-01,   7.40786672e-01,\n",
       "         5.23776591e-01,   6.82544649e-01,  -4.53914329e-02,\n",
       "        -7.80235827e-02,   6.27336025e-01,  -3.79631341e-01,\n",
       "        -5.98189890e-01,  -3.83387983e-01,   1.17137527e+00,\n",
       "         2.91319638e-01,   2.18595192e-01,  -1.71394086e+00,\n",
       "         5.62272668e-01], dtype=float32)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the actual vector for a word:\n",
    "\n",
    "model.docvecs.doctag_syn0[word2id['railing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Science Text and Seq (Python 3)",
   "language": "python",
   "name": "python3ds"
   },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
