{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "Read in data using input_data function. The result is a tensor of dimension [$n$, 784] where $n$ is the number of points. 784 comes from the size of the image (28x28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mypath/train-images-idx3-ubyte.gz\n",
      "Extracting /mypath/train-labels-idx1-ubyte.gz\n",
      "Extracting /mypath/t10k-images-idx3-ubyte.gz\n",
      "Extracting /mypath/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"mypath\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(5000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape)\n",
    "print(mnist.test.images.shape)\n",
    "print(mnist.validation.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Softmax Regression\n",
    "\n",
    "We will create a simple one-layer neural network (i.e. of the form $y=softmax(Wx+b)$)\n",
    "\n",
    "Everything in TF is done va symbolic variables that build a graph to be executed. \n",
    "\n",
    "We start with as a placeholder for the input (the None tells us that the input can be of any size). We also initialized $W$ and $b$ to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Cross-Entropy\n",
    "\n",
    "We will train using a cross-entropy loss. To do this, we need to first compute $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yhat = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum( yhat * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "Up to this point, we have created a graph of objects telling TF what our input, weights and output looks like, wha the loss function is and how the model is trained. We now have to actually run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_iterations = 1000\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict = {x: batch_xs, yhat: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We can assess the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91949999"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_num = tf.argmax(y,1) #convert from one hot to numeric representation\n",
    "yhat_num = tf.argmax(yhat,1)\n",
    "is_correct = tf.equal(y_num, yhat_num) #need to run to get into local environment\n",
    "\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "sess.run(accuracy, feed_dict={x:mnist.test.images, yhat: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>yhat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1109</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>929</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>903</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>952</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "yhat    0     1    2    3    4    5    6    7    8    9\n",
       "y                                                      \n",
       "0     950     0    4    3    1    7    6    2    4    9\n",
       "1       0  1109    7    1    2    4    3    7   12    6\n",
       "2       3     3  929   26    4    2    4   24    9    1\n",
       "3       2     2   11  893    1   22    1    6   18    8\n",
       "4       0     0    6    0  903    6    9    6    8   31\n",
       "5       7     2    6   37    0  774   10    1   30   10\n",
       "6      12     4   16    4   17   21  922    0   12    1\n",
       "7       3     2   11   17    3    8    1  952   14   32\n",
       "8       3    13   34   23    9   42    2    2  864   12\n",
       "9       0     0    8    6   42    6    0   28    3  899"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame({'y':  y_num.eval(session=sess, feed_dict={x:mnist.test.images, yhat: mnist.test.labels}), \\\n",
    "                        'yhat' : yhat_num.eval(session=sess, feed_dict={x:mnist.test.images, yhat: mnist.test.labels})})\n",
    "\n",
    "pd.crosstab(results.y, results.yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer ConvNet\n",
    "\n",
    "Let's try a more complicated model. We first build some functions which will simplify the model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we don't want zero weights to start this time; we will either want some noise or a non-zero constant\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# we need to define how we do convolutions and pooling\n",
    "# this is max pooling on 2x2 blocks and convolutions of stride one, zero-padded\n",
    "#these functions are solely for convenience and could be specified at each step instead\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and Second Conv Layers\n",
    "\n",
    "We add a first layer to model - a convolution and max-pooling, done on a 5x5 patch and computing 32 features. We only have 1 channel to worry about, as well as a bias vector on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1]) #convert image to the format we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the actuall convolving, ReLU and pooling\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer and Dropout and Softmax\n",
    "\n",
    "Finally, we add the fully connected layer and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_dense1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_dense1 = bias_variable([1024])\n",
    "\n",
    "h_pool_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_dense1 = tf.nn.relu(tf.matmul(h_pool_flat, W_dense1) + b_dense1) \n",
    "\n",
    "#dropout prob\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_dense1_drop = tf.nn.dropout(h_dense1, keep_prob)\n",
    "\n",
    "#output/softmax\n",
    "\n",
    "W_dense2 = weight_variable([1024, 10])\n",
    "b_dense2 = bias_variable([10])\n",
    "\n",
    "y_conv =  tf.matmul(h_dense1_drop, W_dense2) + b_dense2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_7:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Current Testing Accuracy 0.0658\n",
      "Step 100, Current Testing Accuracy 0.8456\n",
      "Step 200, Current Testing Accuracy 0.9081\n",
      "Step 300, Current Testing Accuracy 0.9307\n",
      "Step 400, Current Testing Accuracy 0.9395\n",
      "Step 500, Current Testing Accuracy 0.941\n",
      "Step 600, Current Testing Accuracy 0.9524\n",
      "Step 700, Current Testing Accuracy 0.9579\n",
      "Step 800, Current Testing Accuracy 0.9583\n",
      "Step 900, Current Testing Accuracy 0.9621\n",
      "Done! Test Accuracy 0.9643\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "yconv_num = tf.argmax(y_conv, 1) #convert from one hot to numeric representation\n",
    "y_num = tf.argmax(y_ ,1)\n",
    "is_correct = tf.equal(yconv_num, y_num) #need to run to get into local environment\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "sess2 = tf.Session()\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "\n",
    "num_iterations = 1000\n",
    "batch_size = 50\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    if i%100 == 0:\n",
    "        test_accuracy = accuracy.eval(session=sess2,feed_dict={x:mnist.test.images,y_: mnist.test.labels, keep_prob:1.0})\n",
    "        print(\"Step %d, Current Testing Accuracy %g\" %(i, test_accuracy))\n",
    "\n",
    "    fd = {x:batch[0],y_: batch[1], keep_prob:0.5}\n",
    "    sess2.run(train_step, feed_dict=fd)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy.eval(session=sess2,feed_dict={x:mnist.test.images,y_: mnist.test.labels, keep_prob:1.0})\n",
    "print(\"Done! Test Accuracy %g\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess2.close()\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Science for SIGINT (Python 3)",
   "language": "python",
   "name": "python3ds"
   },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
