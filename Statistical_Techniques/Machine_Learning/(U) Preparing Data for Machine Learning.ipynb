{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION: UNCLASSIFIED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# An Example of Preparing Data for Machine Learning\n",
    "\n",
    "Machine learning tends to work with data that has nice numeric vectors. You'll note that the clustering and t-SNE notebooks both assume that your data is already in a purely numeric numpy array. In practice data rarely shows up in such a nice form, and one needs to do a certain amount of preprocessing to make it all \"pretty\" for standard machine learning tools. In this notebook we'll step through an example of taking data from a pandas dataframe of mixed data types all the way to numeric vectors ready for clustering. Fortunately for us scikit-learn comes equipped with a number of tools to help, and pandas itself comes with some useful tricks. Thus the first thing we'll do is load the appropriate libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we need some data to demonstrate on. I've chosen the standard \"titanic\" dataset to work with. It is available [here](https://git.cse-cst.gc.ca/projects/DM/repos/notebooks/browse/data/titanic.csv). The first thing we need to do is get the data loaded. Pandas can help with that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So we can see we have a complex dataframe (see [Visualising Dataframes with Seaborn](http://jupyter.sigint.cse:8080/urls/git.cse-cst.gc.ca/projects/DM/repos/notebooks/raw/Data_Exploration_and_Visualization/Visualising%20Dataframes%20with%20Seaborn.ipynb?at=refs%2Fheads%2Fmaster) for some exploration of this dataset elsewhere). It has some numeric data, like ``age``, and ``fare``, but there are boolean values like ``survived`` and ``adult_male``, and then there are string valued columns like ``sex``, ``class`` and ``embark_town``. Worse still we also have ``deck`` which has missing values (and other columns may also have missing values!). We somehow need to transform all of this into something we can pass to, say, clustering. How do we make it all numeric and nice?\n",
    "\n",
    "The first step is to make use of pandas itself. Pandas has a very handy function called ``get_dummies`` which looks for string valued columns like ``class`` and ``sex`` for which the data is drawn from a set of categories and converts them into numeric columns. It does that by creating a new column for each value in each category and encoding a 0 or 1 for each observation. For those in the know this is called \"one-hot encoding\" of categorical data. Pandas makes that easy. Next we need to get jkusty the numerical data from the dataframe. Again pandas makes this easy via the ``select_dtypes`` which will select out columns based on their datatype. We simply need to tell this method to use ``np.number`` (a generic numeric class from numpy) and it will magically return a dataframe with just the numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>22.00</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>7.25</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>7.925</td>\n",
       "      <td>53.1</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>21.075</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>30.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_female</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked_C</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked_Q</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked_S</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_First</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_Second</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_Third</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who_child</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who_man</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who_woman</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_A</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_B</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_C</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_D</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_E</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_F</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_G</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alive_no</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alive_yes</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0        1       2     3      4       5        6  \\\n",
       "survived                  0.00   1.0000   1.000   1.0   0.00  0.0000   0.0000   \n",
       "pclass                    3.00   1.0000   3.000   1.0   3.00  3.0000   1.0000   \n",
       "age                      22.00  38.0000  26.000  35.0  35.00     NaN  54.0000   \n",
       "sibsp                     1.00   1.0000   0.000   1.0   0.00  0.0000   0.0000   \n",
       "parch                     0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "fare                      7.25  71.2833   7.925  53.1   8.05  8.4583  51.8625   \n",
       "sex_female                0.00   1.0000   1.000   1.0   0.00  0.0000   0.0000   \n",
       "sex_male                  1.00   0.0000   0.000   0.0   1.00  1.0000   1.0000   \n",
       "embarked_C                0.00   1.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "embarked_Q                0.00   0.0000   0.000   0.0   0.00  1.0000   0.0000   \n",
       "embarked_S                1.00   0.0000   1.000   1.0   1.00  0.0000   1.0000   \n",
       "class_First               0.00   1.0000   0.000   1.0   0.00  0.0000   1.0000   \n",
       "class_Second              0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "class_Third               1.00   0.0000   1.000   0.0   1.00  1.0000   0.0000   \n",
       "who_child                 0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "who_man                   1.00   0.0000   0.000   0.0   1.00  1.0000   1.0000   \n",
       "who_woman                 0.00   1.0000   1.000   1.0   0.00  0.0000   0.0000   \n",
       "deck_A                    0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "deck_B                    0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "deck_C                    0.00   1.0000   0.000   1.0   0.00  0.0000   0.0000   \n",
       "deck_D                    0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "deck_E                    0.00   0.0000   0.000   0.0   0.00  0.0000   1.0000   \n",
       "deck_F                    0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "deck_G                    0.00   0.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "embark_town_Cherbourg     0.00   1.0000   0.000   0.0   0.00  0.0000   0.0000   \n",
       "embark_town_Queenstown    0.00   0.0000   0.000   0.0   0.00  1.0000   0.0000   \n",
       "embark_town_Southampton   1.00   0.0000   1.000   1.0   1.00  0.0000   1.0000   \n",
       "alive_no                  1.00   0.0000   0.000   0.0   1.00  1.0000   1.0000   \n",
       "alive_yes                 0.00   1.0000   1.000   1.0   0.00  0.0000   0.0000   \n",
       "\n",
       "                              7        8        9  \n",
       "survived                  0.000   1.0000   1.0000  \n",
       "pclass                    3.000   3.0000   2.0000  \n",
       "age                       2.000  27.0000  14.0000  \n",
       "sibsp                     3.000   0.0000   1.0000  \n",
       "parch                     1.000   2.0000   0.0000  \n",
       "fare                     21.075  11.1333  30.0708  \n",
       "sex_female                0.000   1.0000   1.0000  \n",
       "sex_male                  1.000   0.0000   0.0000  \n",
       "embarked_C                0.000   0.0000   1.0000  \n",
       "embarked_Q                0.000   0.0000   0.0000  \n",
       "embarked_S                1.000   1.0000   0.0000  \n",
       "class_First               0.000   0.0000   0.0000  \n",
       "class_Second              0.000   0.0000   1.0000  \n",
       "class_Third               1.000   1.0000   0.0000  \n",
       "who_child                 1.000   0.0000   1.0000  \n",
       "who_man                   0.000   0.0000   0.0000  \n",
       "who_woman                 0.000   1.0000   0.0000  \n",
       "deck_A                    0.000   0.0000   0.0000  \n",
       "deck_B                    0.000   0.0000   0.0000  \n",
       "deck_C                    0.000   0.0000   0.0000  \n",
       "deck_D                    0.000   0.0000   0.0000  \n",
       "deck_E                    0.000   0.0000   0.0000  \n",
       "deck_F                    0.000   0.0000   0.0000  \n",
       "deck_G                    0.000   0.0000   0.0000  \n",
       "embark_town_Cherbourg     0.000   0.0000   1.0000  \n",
       "embark_town_Queenstown    0.000   0.0000   0.0000  \n",
       "embark_town_Southampton   1.000   1.0000   0.0000  \n",
       "alive_no                  1.000   0.0000   0.0000  \n",
       "alive_yes                 0.000   1.0000   1.0000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data = pd.get_dummies(titanic).select_dtypes([np.number])\n",
    "numeric_data.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This looks great! Except we still have those missing values. We can't actually run many machine learning tools while we have NaNs in our data. We need a way to get rid of them somehow. Now, we could have dropped the NAs in pandas, but we would end up losing a lot of data from a small dataset, so instead we'll try to impute the values. Scikit-learn provides an imputer class. In our case we'll use the strategy ``'mean'`` which will fill missing values with the mean value of the feature column. Other strategies, such as ``'median'`` and ``'most_frequent'`` also exist, and do exactly what you would expect. The setup here looks a little odd -- we create an imputer object, fit it to the data and then apply a transform to the same data. Why so complicated? We'll come back to this later, but the main thing to note is that we can *train* one one dataset, and then apply what we learned to a different *test* dataset. If we are doing proper cross validation then this is important (when building classifiers if you judge your accuracy by how well you do on the data you trained on you'll have a bad time -- you need to train on one dataset, and then see how things work on new unseen data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   3.        ,  22.        , ...,   1.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  1.        ,   1.        ,  38.        , ...,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,   3.        ,  26.        , ...,   1.        ,\n",
       "          0.        ,   1.        ],\n",
       "       ..., \n",
       "       [  0.        ,   3.        ,  29.69911765, ...,   1.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  1.        ,   1.        ,  26.        , ...,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  0.        ,   3.        ,  32.        , ...,   0.        ,\n",
       "          1.        ,   0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = preprocessing.Imputer(strategy='mean')\n",
    "imputer.fit(numeric_data)\n",
    "filled_data = imputer.transform(numeric_data)\n",
    "filled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Okay we filled in all the NaN values with a reasonable guess. Our next problem is that the data isn't exactly all on the same scale. Ages range from 2 to 80, while ``pclass`` ranges from 1 to 3. We would like to make all our features roughly comparable, especially if we are going to be clustering them. To do that we want to scale the data so each feature is on the same scale -- in practice we could subtract the mean and divide by the standard deviation (if our data was normally distributed). Since this sort of thing is a common operation scikit-learn provides tools to do this. If you want to just do the standard mean and standard deviation trick then you can use ``StandardScaler``. To be a little more robust to outliers we will use ``RobustScaler`` which uses robust statistics (such as median, and inter-quartile range) to do the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        , -0.59223982, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        , -2.        ,  0.63852941, ..., -1.        ,\n",
       "        -1.        ,  1.        ],\n",
       "       [ 1.        ,  0.        , -0.28454751, ...,  0.        ,\n",
       "        -1.        ,  1.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        , -2.        , -0.28454751, ..., -1.        ,\n",
       "        -1.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.17699095, ..., -1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(filled_data)\n",
    "scaled_data = scaler.transform(filled_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One last thing: we have some redundancy in our features. You'll note that ``embarked_C`` and ``embark_town_Cherbourg`` from our numeric dataframe will be effectively the same. Other features will potentially be highly correlated as well. It would be nice to remove some of this obvious redundancy. We can do this by using Principal Component Analysis to reduce the overall dimension of our dataset, effectively stripping out correlated features. In scikit-learn this is done via the ``PCA`` class. Again it is the same ``fit`` and then ``transform`` process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.46723322,  0.60596188,  0.96579931, ..., -0.0108578 ,\n",
       "        -0.00542452, -0.03222112],\n",
       "       [ 2.52931345, -0.47960619, -1.46691513, ..., -0.26042646,\n",
       "        -0.01231339,  0.04115801],\n",
       "       [-1.07611019,  0.21351006, -1.61625174, ..., -0.03076527,\n",
       "        -0.0157039 ,  0.05708236],\n",
       "       ..., \n",
       "       [-0.39814968,  1.41296638, -0.21753861, ...,  0.02286474,\n",
       "         0.01000691,  0.05320269],\n",
       "       [ 0.51949812, -1.09365786, -0.82545504, ..., -0.29761009,\n",
       "        -0.03558347, -0.04695924],\n",
       "       [-1.44792646, -0.50599888,  0.62005618, ...,  0.01709805,\n",
       "        -0.01322648, -0.04635845]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducer = decomposition.PCA(n_components=15)\n",
    "reducer.fit(scaled_data)\n",
    "reduced_data = reducer.transform(scaled_data)\n",
    "reduced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have data that is numeric, has non missing values, is all on the same scale, and has some of the redundancy removed. We are in a place where we could, for example, hand the data to a clustering algorithm. Before I do that, however, I am going to demonstrate another feature of scikit-learn: pipelines. When you have some data to which you want to apply a set of transforms and then run an estimator (a classifier, a clusterer, a regression etc.) you can fit all the pieces together in a pipeline object. Then we can call ``fit`` and ``predict`` on the pipeline as a whole and scikit-learn will take care of passing the data from one transform to the next all the way to our final estimator. To construct a pipeline simply instantiate all the transformers and the estimator you want to use and pass them as an ordered list to the ``Pipeline`` class (with names so you can later extract interim data from the pipeline if you wish). You can see an example below where we construct the same transforms as above, along with a clusterer object, and hand it all to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imputer = preprocessing.Imputer(strategy='mean')\n",
    "scaler = preprocessing.RobustScaler()\n",
    "reducer = decomposition.PCA(n_components=15)\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=20)\n",
    "cluster_pipeline = pipeline.Pipeline([('impute', imputer),\n",
    "                                      ('scale', scaler),\n",
    "                                      ('pca', reducer),\n",
    "                                      ('hdbscan', clusterer)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can call ``fit`` and ``predict`` on the pipeline as a whole on the original source data. Since we are doing clustering we are going to predict the data we fit with, but if this was, say, a classification problem then we could fit the pipeline to the training data and then run predict on the test set. Putting all your data in a pipeline like this makes it easier to work with, and consistent when you rerun things, rather than passing the data around yourself by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  3, -1, -1,  1, -1, -1, -1, -1, -1, -1,  5, -1, -1, -1, -1,\n",
       "       -1,  3, -1,  4, -1, -1, -1, -1, -1,  0, -1,  7,  6, -1, -1,  7, -1,\n",
       "       -1, -1,  0,  5, -1, -1,  3, -1,  0, -1,  7,  6,  1,  7, -1,  3, -1,\n",
       "        5, -1,  2, -1, -1,  2,  0, -1, -1,  0, -1, -1, -1, -1, -1,  2,  5,\n",
       "       -1, -1,  4, -1, -1,  0, -1, -1,  6,  6, -1,  3,  5, -1,  7, -1,  2,\n",
       "       -1, -1,  6, -1,  5,  6,  5, -1, -1, -1,  6, -1, -1,  2,  4,  3,  6,\n",
       "       -1, -1, -1,  6, -1, -1, -1,  7, -1, -1,  5,  3, -1,  5, -1,  4, -1,\n",
       "       -1, -1,  6, -1,  2, -1, -1,  1, -1, -1, -1,  0,  5, -1,  2,  4,  0,\n",
       "       -1, -1, -1, -1, -1, -1,  3,  1,  4, -1, -1, -1, -1,  4,  4, -1, -1,\n",
       "       -1,  6, -1,  7,  6,  6, -1, -1,  2, -1, -1, -1, -1, -1, -1,  4, -1,\n",
       "       -1, -1, -1,  5, -1, -1, -1, -1,  4, -1, -1,  0, -1, -1, -1, -1,  7,\n",
       "       -1,  1, -1,  2,  4, -1, -1, -1, -1,  1, -1,  7, -1,  6, -1, -1,  0,\n",
       "       -1, -1, -1,  0,  7, -1,  5,  2,  5,  4,  1, -1,  3,  4, -1,  4, -1,\n",
       "        4, -1,  6, -1,  5, -1,  5,  4, -1, -1,  6, -1, -1,  4,  3,  4, -1,\n",
       "        4,  4, -1,  7,  4,  5,  0, -1,  3, -1, -1,  4,  6,  3, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1,  1, -1, -1, -1,  7,  4, -1, -1, -1, -1,  4, -1,\n",
       "        2, -1,  7, -1, -1,  4, -1, -1, -1,  6, -1, -1,  4,  0, -1,  5, -1,\n",
       "        7, -1, -1, -1,  3,  5, -1,  0, -1, -1, -1,  7, -1, -1, -1,  6, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1,  6,  4,  3,  2,  4, -1, -1,  5, -1, -1,\n",
       "        2, -1, -1, -1,  2,  3, -1, -1,  4, -1, -1, -1,  6, -1, -1, -1,  4,\n",
       "       -1, -1,  4,  4,  4,  2,  2,  3, -1, -1,  5, -1, -1, -1,  0,  6, -1,\n",
       "       -1,  7,  7, -1, -1, -1, -1,  1,  6, -1, -1,  7, -1, -1, -1,  5, -1,\n",
       "       -1, -1, -1, -1,  0,  5, -1, -1, -1, -1,  6, -1, -1,  2,  1, -1, -1,\n",
       "       -1, -1, -1, -1,  5,  3,  4,  4,  2, -1,  5,  3, -1,  3,  4, -1, -1,\n",
       "        5, -1,  6,  1, -1,  4, -1,  3,  2, -1,  4, -1,  0,  1,  6,  3, -1,\n",
       "        6,  2,  2,  1, -1, -1,  3,  2, -1, -1, -1, -1, -1, -1,  4,  2,  5,\n",
       "       -1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  6,  0, -1, -1,  2,\n",
       "        1, -1, -1,  4,  4,  6, -1,  4, -1,  1, -1,  6, -1, -1, -1,  3, -1,\n",
       "        4, -1,  5, -1, -1,  4, -1, -1, -1, -1, -1, -1,  6, -1, -1,  5, -1,\n",
       "       -1,  5,  0, -1, -1, -1,  5, -1,  7,  7,  3, -1, -1, -1, -1, -1, -1,\n",
       "        1,  6, -1, -1,  5,  4,  2,  1,  2, -1, -1,  5,  0, -1,  0,  1,  2,\n",
       "       -1, -1, -1, -1,  0,  0, -1,  3, -1,  4, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  2, -1, -1, -1, -1,  4,  1,  0, -1, -1, -1, -1, -1, -1,  1,\n",
       "       -1,  4,  6,  3, -1,  5, -1,  0, -1, -1, -1, -1,  7, -1, -1,  2, -1,\n",
       "       -1, -1,  2, -1,  4, -1,  0, -1,  4, -1,  5,  6, -1, -1, -1, -1,  4,\n",
       "       -1,  2, -1,  0, -1, -1,  6,  4, -1, -1, -1,  6, -1, -1, -1, -1,  6,\n",
       "        7,  1, -1, -1, -1,  3, -1,  4,  0, -1, -1,  5, -1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1,  2, -1,  4, -1, -1,  5, -1, -1, -1, -1, -1,\n",
       "        5, -1,  6,  3,  6,  2,  5,  7,  7, -1,  6, -1,  4, -1, -1,  0, -1,\n",
       "       -1, -1, -1,  4,  6, -1, -1,  2, -1, -1, -1,  4,  5, -1, -1, -1, -1,\n",
       "        7, -1,  5, -1, -1, -1, -1, -1,  5, -1, -1, -1, -1,  0, -1,  4, -1,\n",
       "        7, -1, -1, -1, -1, -1,  1, -1,  4,  2, -1, -1, -1, -1, -1, -1,  6,\n",
       "        4, -1, -1,  2,  1, -1, -1, -1,  4,  4, -1,  5, -1,  7,  4,  3, -1,\n",
       "       -1,  4,  4,  4, -1, -1, -1,  6,  6, -1, -1, -1, -1, -1, -1, -1,  2,\n",
       "       -1,  1, -1, -1, -1,  5, -1, -1,  6,  4, -1, -1, -1, -1,  0, -1, -1,\n",
       "       -1, -1,  7,  1, -1, -1, -1, -1,  0, -1,  5,  1, -1,  1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1,  1,  4, -1, -1,  5,  4, -1,  3,  0,\n",
       "        3,  4,  2, -1, -1, -1,  6, -1,  3,  4, -1, -1, -1,  4, -1,  6, -1,\n",
       "        3, -1, -1, -1, -1, -1, -1,  3, -1,  1, -1, -1,  1, -1, -1, -1,  0,\n",
       "        5,  5, -1,  5,  6, -1, -1,  5,  4, -1,  0, -1, -1, -1,  0,  4, -1,\n",
       "       -1, -1, -1, -1, -1,  3, -1, -1, -1,  0, -1,  4, -1, -1,  4,  2, -1,\n",
       "        4,  6, -1, -1, -1, -1, -1, -1, -1,  5,  5,  6, -1,  2, -1,  3,  4,\n",
       "       -1, -1,  4, -1, -1, -1,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels = cluster_pipeline.fit_predict(numeric_data)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What did we get out? Well we can have a look at one of the clusters from the original dataframe to get an idea ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8375</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6833</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "2           1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "18          0       3  female  31.0      1      0  18.0000        S  Third   \n",
       "40          0       3  female  40.0      1      0   9.4750        S  Third   \n",
       "49          0       3  female  18.0      1      0  17.8000        S  Third   \n",
       "79          1       3  female  30.0      0      0  12.4750        S  Third   \n",
       "100         0       3  female  28.0      0      0   7.8958        S  Third   \n",
       "113         0       3  female  20.0      1      0   9.8250        S  Third   \n",
       "142         1       3  female  24.0      1      0  15.8500        S  Third   \n",
       "216         1       3  female  27.0      0      0   7.9250        S  Third   \n",
       "235         0       3  female   NaN      0      0   7.5500        S  Third   \n",
       "246         0       3  female  25.0      0      0   7.7750        S  Third   \n",
       "251         0       3  female  29.0      1      1  10.4625        S  Third   \n",
       "293         0       3  female  24.0      0      0   8.8500        S  Third   \n",
       "315         1       3  female  26.0      0      0   7.8542        S  Third   \n",
       "328         1       3  female  31.0      1      1  20.5250        S  Third   \n",
       "347         1       3  female   NaN      1      0  16.1000        S  Third   \n",
       "396         0       3  female  31.0      0      0   7.8542        S  Third   \n",
       "402         0       3  female  21.0      1      0   9.8250        S  Third   \n",
       "404         0       3  female  20.0      0      0   8.6625        S  Third   \n",
       "415         0       3  female   NaN      0      0   8.0500        S  Third   \n",
       "423         0       3  female  28.0      1      1  14.4000        S  Third   \n",
       "431         1       3  female   NaN      1      0  16.1000        S  Third   \n",
       "474         0       3  female  22.0      0      0   9.8375        S  Third   \n",
       "503         0       3  female  37.0      0      0   9.5875        S  Third   \n",
       "534         0       3  female  30.0      0      0   8.6625        S  Third   \n",
       "564         0       3  female   NaN      0      0   8.0500        S  Third   \n",
       "617         0       3  female  26.0      1      0  16.1000        S  Third   \n",
       "649         1       3  female  23.0      0      0   7.5500        S  Third   \n",
       "729         0       3  female  25.0      1      0   7.9250        S  Third   \n",
       "797         1       3  female  31.0      0      0   8.6833        S  Third   \n",
       "799         0       3  female  30.0      1      1  24.1500        S  Third   \n",
       "807         0       3  female  18.0      0      0   7.7750        S  Third   \n",
       "816         0       3  female  23.0      0      0   7.9250        S  Third   \n",
       "823         1       3  female  27.0      0      1  12.4750        S  Third   \n",
       "855         1       3  female  18.0      0      1   9.3500        S  Third   \n",
       "882         0       3  female  22.0      0      0  10.5167        S  Third   \n",
       "\n",
       "       who adult_male deck  embark_town alive  alone  \n",
       "2    woman      False  NaN  Southampton   yes   True  \n",
       "18   woman      False  NaN  Southampton    no  False  \n",
       "40   woman      False  NaN  Southampton    no  False  \n",
       "49   woman      False  NaN  Southampton    no  False  \n",
       "79   woman      False  NaN  Southampton   yes   True  \n",
       "100  woman      False  NaN  Southampton    no   True  \n",
       "113  woman      False  NaN  Southampton    no  False  \n",
       "142  woman      False  NaN  Southampton   yes  False  \n",
       "216  woman      False  NaN  Southampton   yes   True  \n",
       "235  woman      False  NaN  Southampton    no   True  \n",
       "246  woman      False  NaN  Southampton    no   True  \n",
       "251  woman      False    G  Southampton    no  False  \n",
       "293  woman      False  NaN  Southampton    no   True  \n",
       "315  woman      False  NaN  Southampton   yes   True  \n",
       "328  woman      False  NaN  Southampton   yes  False  \n",
       "347  woman      False  NaN  Southampton   yes  False  \n",
       "396  woman      False  NaN  Southampton    no   True  \n",
       "402  woman      False  NaN  Southampton    no  False  \n",
       "404  woman      False  NaN  Southampton    no   True  \n",
       "415  woman      False  NaN  Southampton    no   True  \n",
       "423  woman      False  NaN  Southampton    no  False  \n",
       "431  woman      False  NaN  Southampton   yes  False  \n",
       "474  woman      False  NaN  Southampton    no   True  \n",
       "503  woman      False  NaN  Southampton    no   True  \n",
       "534  woman      False  NaN  Southampton    no   True  \n",
       "564  woman      False  NaN  Southampton    no   True  \n",
       "617  woman      False  NaN  Southampton    no  False  \n",
       "649  woman      False  NaN  Southampton   yes   True  \n",
       "729  woman      False  NaN  Southampton    no  False  \n",
       "797  woman      False  NaN  Southampton   yes   True  \n",
       "799  woman      False  NaN  Southampton    no  False  \n",
       "807  woman      False  NaN  Southampton    no   True  \n",
       "816  woman      False  NaN  Southampton    no   True  \n",
       "823  woman      False    E  Southampton   yes  False  \n",
       "855  woman      False  NaN  Southampton   yes  False  \n",
       "882  woman      False  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[cluster_labels == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also group the dataframe by the cluster labels and then look at the average values of various categories to see what the clustering has seprated out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>pclass</th>\n",
       "      <th>fare</th>\n",
       "      <th>adult_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.484171</td>\n",
       "      <td>30.331571</td>\n",
       "      <td>2.098696</td>\n",
       "      <td>45.535514</td>\n",
       "      <td>0.536313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135135</td>\n",
       "      <td>28.095238</td>\n",
       "      <td>2.945946</td>\n",
       "      <td>8.609578</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>29.687500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.681119</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.987500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.387805</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>26.161290</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.104631</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.543478</td>\n",
       "      <td>1.873418</td>\n",
       "      <td>17.135337</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.147059</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.012247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.093750</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.990822</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>20.357143</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.160868</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survived        age    pclass       fare  adult_male\n",
       "-1  0.484171  30.331571  2.098696  45.535514    0.536313\n",
       " 0  0.135135  28.095238  2.945946   8.609578    1.000000\n",
       " 1  0.062500  29.687500  3.000000   9.681119    1.000000\n",
       " 2  1.000000  31.987500  2.000000  19.387805    0.000000\n",
       " 3  0.333333  26.161290  3.000000  11.104631    0.000000\n",
       " 4  0.000000  33.543478  1.873418  17.135337    1.000000\n",
       " 5  0.000000  21.147059  3.000000   8.012247    1.000000\n",
       " 6  0.000000  29.093750  3.000000   7.990822    1.000000\n",
       " 7  0.785714  20.357143  3.000000   9.160868    0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(cluster_labels)[['survived', 'age', 'pclass', 'fare', 'adult_male']].mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Data Science for SIGINT (Python 3)",
   "language": "python",
   "name": "python3ds"
   },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
